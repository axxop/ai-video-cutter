#!/usr/bin/env python3
"""
å®Œæ•´è§†é¢‘ç”Ÿæˆæµç¨‹ï¼š
1. è§£ææ–‡æ¡ˆè„šæœ¬ï¼ˆå¸¦è¡Œå·èŒƒå›´ï¼‰
2. å¹¶è¡Œç”Ÿæˆ TTS é…éŸ³ï¼ˆç¼“å­˜ï¼‰
3. å¹¶è¡Œè°ƒç”¨ DeepSeek ç»†åŒ–è§†é¢‘ç‰‡æ®µé€‰æ‹©ï¼ˆç¼“å­˜ï¼‰
4. å¹¶è¡Œæå–è§†é¢‘ç‰‡æ®µå¹¶æ·»åŠ é…éŸ³+å­—å¹•ï¼ˆç¼“å­˜ï¼‰
5. åˆæˆæœ€ç»ˆè§†é¢‘
"""

import os
import json
import re
import hashlib
import argparse
import shutil
from pathlib import Path
from typing import List, Dict, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from openai import OpenAI

# å¯¼å…¥ç°æœ‰æ¨¡å—
from video_compressor import SRTParser, VideoClipFinder
from generate_tts import parse_script as parse_tts_script
from tts_client import CosyVoiceClient
from config.cosyvoice_config import CosyVoiceConfig


class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir: str = ".cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
        # å­ç›®å½•
        self.tts_cache_dir = self.cache_dir / "tts"
        self.clip_cache_dir = self.cache_dir / "clips"
        self.meta_cache_dir = self.cache_dir / "meta"
        
        for d in [self.tts_cache_dir, self.clip_cache_dir, self.meta_cache_dir]:
            d.mkdir(exist_ok=True)
    
    def get_hash(self, content: str) -> str:
        """ç”Ÿæˆå†…å®¹å“ˆå¸Œ"""
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def get_tts_cache_path(self, text: str, speaker: str) -> Path:
        """è·å– TTS ç¼“å­˜è·¯å¾„"""
        cache_key = f"{speaker}:{text}"
        cache_hash = self.get_hash(cache_key)
        return self.tts_cache_dir / f"{cache_hash}.wav"
    
    def get_clip_cache_path(self, clip_hash: str) -> Path:
        """è·å–è§†é¢‘ç‰‡æ®µç¼“å­˜è·¯å¾„"""
        return self.clip_cache_dir / f"{clip_hash}.mp4"
    
    def get_meta_cache_path(self, meta_type: str, key: str) -> Path:
        """è·å–å…ƒæ•°æ®ç¼“å­˜è·¯å¾„"""
        cache_hash = self.get_hash(key)
        return self.meta_cache_dir / f"{meta_type}_{cache_hash}.json"
    
    def save_json(self, path: Path, data: dict):
        """ä¿å­˜ JSON æ•°æ®"""
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def load_json(self, path: Path) -> dict:
        """åŠ è½½ JSON æ•°æ®"""
        if not path.exists():
            return None
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def clear(self):
        """æ¸…ç†æ‰€æœ‰ç¼“å­˜"""
        shutil.rmtree(self.cache_dir)
        self.__init__(str(self.cache_dir))


class ScriptParser:
    """æ–‡æ¡ˆè„šæœ¬è§£æå™¨"""
    
    @staticmethod
    def parse_script_file(script_file: str) -> List[Dict]:
        """
        è§£ææ–‡æ¡ˆè„šæœ¬æ–‡ä»¶
        æ ¼å¼: [æ—¶é—´] [è¡Œå·] å†…å®¹
        
        Returns:
            [{'duration': 15, 'line_range': [1, 50], 'text': '...'}]
        """
        segments = []
        
        with open(script_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                
                # è§£ææ ¼å¼: [15s] [1-50] å†…å®¹...
                match = re.match(r'\[(\d+)s\]\s*\[(\d+)-(\d+)\]\s*(.+)', line)
                if match:
                    duration = int(match.group(1))
                    line_start = int(match.group(2))
                    line_end = int(match.group(3))
                    text = match.group(4)
                    
                    segments.append({
                        'duration': duration,
                        'line_range': [line_start, line_end],
                        'text': text
                    })
                else:
                    print(f"âš ï¸  æ— æ³•è§£æè¡Œ: {line[:60]}...")
        
        return segments


class ParallelTTSGenerator:
    """å¹¶è¡Œ TTS ç”Ÿæˆå™¨ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    
    def __init__(self, cache_manager: CacheManager, speaker_id: str = "é¾™ç™½èŠ", 
                 api_key: str = None, max_workers: int = 4):
        self.cache_manager = cache_manager
        self.speaker_id = speaker_id
        self.max_workers = max_workers
        
        # ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è·å– API key
        bailian_key = api_key or os.getenv("BAILIAN_API_KEY")
        if not bailian_key:
            raise ValueError(
                "BAILIAN_API_KEY is required for TTS generation. "
                "Please set the BAILIAN_API_KEY environment variable or pass --api-key argument."
            )
        
        # åˆå§‹åŒ– TTS å®¢æˆ·ç«¯
        config = CosyVoiceConfig(
            api_key=bailian_key,
            speaker_id=speaker_id,
            output_dir=str(cache_manager.tts_cache_dir)
        )
        self.tts_client = CosyVoiceClient(config)
    
    def generate_one(self, segment: Dict, index: int) -> Dict:
        """ç”Ÿæˆå•ä¸ª TTS éŸ³é¢‘ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        text = segment['text']
        duration = segment['duration']
        
        # æ£€æŸ¥ç¼“å­˜
        cache_path = self.cache_manager.get_tts_cache_path(text, self.speaker_id)
        
        if cache_path.exists():
            print(f"  [{index}] âœ“ ä½¿ç”¨ç¼“å­˜ TTS: {cache_path.name}")
            return {
                'index': index,
                'audio_file': str(cache_path),
                'text': text,
                'duration': duration,
                'line_range': segment['line_range'],
                'from_cache': True
            }
        
        # ç”Ÿæˆ TTS
        try:
            print(f"  [{index}] ğŸ¤ ç”Ÿæˆ TTS: {text[:40]}...")
            result = self.tts_client.synthesize(text, str(cache_path))
            
            return {
                'index': index,
                'audio_file': str(cache_path),
                'text': text,
                'duration': duration,
                'line_range': segment['line_range'],
                'from_cache': False
            }
        except Exception as e:
            print(f"  [{index}] âŒ TTS ç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def generate_all(self, segments: List[Dict]) -> List[Dict]:
        """å¹¶è¡Œç”Ÿæˆæ‰€æœ‰ TTS éŸ³é¢‘"""
        print(f"\nğŸ¤ å¹¶è¡Œç”Ÿæˆ TTS éŸ³é¢‘ï¼ˆå¹¶å‘æ•°: {self.max_workers}ï¼‰...")
        
        results = [None] * len(segments)
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {
                executor.submit(self.generate_one, seg, i): i 
                for i, seg in enumerate(segments, 1)
            }
            
            for future in as_completed(futures):
                result = future.result()
                if result:
                    results[result['index'] - 1] = result
        
        # è¿‡æ»¤ None
        results = [r for r in results if r is not None]
        
        cache_count = sum(1 for r in results if r.get('from_cache'))
        print(f"âœ… TTS ç”Ÿæˆå®Œæˆ: {len(results)} ä¸ªéŸ³é¢‘ï¼ˆ{cache_count} ä¸ªæ¥è‡ªç¼“å­˜ï¼‰\n")
        
        return results


class ParallelClipSelector:
    """å¹¶è¡Œè§†é¢‘ç‰‡æ®µé€‰æ‹©å™¨ï¼ˆä½¿ç”¨ DeepSeek ç»†åŒ–ï¼‰"""
    
    def __init__(self, cache_manager: CacheManager, subtitles: List[Dict], 
                 api_key: str = None, max_workers: int = 3):
        self.cache_manager = cache_manager
        self.subtitles = subtitles
        self.max_workers = max_workers
        # ä»ç¯å¢ƒå˜é‡æˆ–å‚æ•°è·å– API key
        deepseek_key = api_key or os.getenv("DEEPSEEK_API_KEY") or os.getenv("OPENAI_API_KEY")
        self.clip_finder = VideoClipFinder(deepseek_key)
    
    def select_one(self, segment: Dict, index: int) -> Dict:
        """
        ä¸ºå•ä¸ªç‰‡æ®µé€‰æ‹©æœ€ä½³è§†é¢‘ç‰‡æ®µï¼ˆå¸¦ç¼“å­˜ï¼‰
        ä½¿ç”¨ DeepSeek åœ¨æŒ‡å®šè¡Œå·èŒƒå›´å†…ç»†åŒ–é€‰æ‹©
        """
        text = segment['text']
        audio_duration = segment['duration']
        line_start, line_end = segment['line_range']
        
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = f"{line_start}-{line_end}:{text}:{audio_duration}"
        cache_path = self.cache_manager.get_meta_cache_path("clip_selection", cache_key)
        
        # æ£€æŸ¥ç¼“å­˜
        cached_result = self.cache_manager.load_json(cache_path)
        if cached_result:
            print(f"  [{index}] âœ“ ä½¿ç”¨ç¼“å­˜ç‰‡æ®µé€‰æ‹©: [{line_start}-{line_end}]")
            cached_result['index'] = index
            return cached_result
        
        # è°ƒç”¨ DeepSeek é€‰æ‹©ç‰‡æ®µ
        print(f"  [{index}] ğŸ¤– DeepSeek é€‰æ‹©ç‰‡æ®µ: [{line_start}-{line_end}] {text[:40]}...")
        
        clip_info = self.clip_finder.find_best_clip(
            text, self.subtitles, line_start, line_end, audio_duration
        )
        
        if not clip_info:
            print(f"  [{index}] âš ï¸  æœªæ‰¾åˆ°åˆé€‚ç‰‡æ®µ")
            return None
        
        # æ·»åŠ å…ƒæ•°æ®
        clip_info['index'] = index
        clip_info['text'] = text
        clip_info['audio_duration'] = audio_duration
        
        # ä¿å­˜ç¼“å­˜
        self.cache_manager.save_json(cache_path, clip_info)
        
        return clip_info
    
    def select_all(self, segments: List[Dict]) -> List[Dict]:
        """å¹¶è¡Œé€‰æ‹©æ‰€æœ‰è§†é¢‘ç‰‡æ®µ"""
        print(f"\nğŸ¤– å¹¶è¡Œé€‰æ‹©è§†é¢‘ç‰‡æ®µï¼ˆå¹¶å‘æ•°: {self.max_workers}ï¼‰...")
        
        results = [None] * len(segments)
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {
                executor.submit(self.select_one, seg, i): i 
                for i, seg in enumerate(segments, 1)
            }
            
            for future in as_completed(futures):
                result = future.result()
                if result:
                    results[result['index'] - 1] = result
        
        # è¿‡æ»¤ None
        results = [r for r in results if r is not None]
        
        print(f"âœ… ç‰‡æ®µé€‰æ‹©å®Œæˆ: {len(results)} ä¸ªç‰‡æ®µ\n")
        
        return results


class ParallelVideoClipper:
    """å¹¶è¡Œè§†é¢‘ç‰‡æ®µæå–å™¨ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    
    def __init__(self, cache_manager: CacheManager, original_video: str, 
                 max_workers: int = 3):
        self.cache_manager = cache_manager
        self.original_video = original_video
        self.max_workers = max_workers
    
    def extract_one(self, clip_info: Dict, audio_file: str, index: int) -> Dict:
        """æå–å•ä¸ªè§†é¢‘ç‰‡æ®µå¹¶æ·»åŠ é…éŸ³+å­—å¹•ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        import subprocess
        import tempfile
        
        start_time = clip_info['start_time']
        end_time = clip_info['end_time']
        text = clip_info['text']
        audio_duration = clip_info['audio_duration']
        
        # è§†é¢‘æ—¶é•¿ = éŸ³é¢‘æ—¶é•¿ + 2 ç§’
        video_duration = audio_duration + 2.0
        
        # è°ƒæ•´ç»“æŸæ—¶é—´
        if (end_time - start_time) > video_duration:
            end_time = start_time + video_duration
        
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = f"{start_time:.2f}-{end_time:.2f}:{audio_file}:{text}"
        cache_hash = self.cache_manager.get_hash(cache_key)
        cache_path = self.cache_manager.get_clip_cache_path(cache_hash)
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_path.exists():
            print(f"  [{index}] âœ“ ä½¿ç”¨ç¼“å­˜ç‰‡æ®µ: {cache_path.name}")
            return {
                'index': index,
                'video_file': str(cache_path),
                'audio_file': audio_file,
                'text': text,
                'from_cache': True
            }
        
        # æå–è§†é¢‘ç‰‡æ®µ
        print(f"  [{index}] âœ‚ï¸  æå–ç‰‡æ®µ: {start_time:.1f}s-{end_time:.1f}s + é…éŸ³")
        
        duration = end_time - start_time
        
        # åˆ›å»ºä¸´æ—¶å­—å¹•æ–‡ä»¶
        srt_file = tempfile.NamedTemporaryFile(mode='w', suffix='.srt', delete=False, encoding='utf-8')
        srt_file.write(f"1\n00:00:00,000 --> {self._format_srt_time(duration)}\n{text}\n")
        srt_file.close()
        
        # FFmpeg å‘½ä»¤ï¼šæå–è§†é¢‘ + æ·»åŠ é…éŸ³ + çƒ§å½•å­—å¹•
        cmd = [
            'ffmpeg', '-y', '-loglevel', 'error',
            '-ss', str(start_time),
            '-i', self.original_video,
            '-i', audio_file,
            '-t', str(duration),
            '-filter_complex',
            f"[0:v]scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2,subtitles={srt_file.name}:force_style='Fontsize=8,PrimaryColour=&H00FFFFFF,OutlineColour=&H00000000,Outline=2,Shadow=1,MarginV=40,Alignment=2'[vout]",
            '-map', '[vout]',
            '-map', '1:a',
            '-c:v', 'libx264',
            '-preset', 'ultrafast',
            '-crf', '23',
            '-c:a', 'aac',
            '-b:a', '128k',
            str(cache_path)
        ]
        
        try:
            subprocess.run(cmd, check=True, timeout=120)
            print(f"  [{index}] âœ… ç‰‡æ®µå·²ä¿å­˜: {cache_path.name}")
        except Exception as e:
            print(f"  [{index}] âŒ æå–å¤±è´¥: {e}")
            return None
        finally:
            try:
                os.unlink(srt_file.name)
            except:
                pass
        
        return {
            'index': index,
            'video_file': str(cache_path),
            'audio_file': audio_file,
            'text': text,
            'from_cache': False
        }
    
    def extract_all(self, clip_selections: List[Dict], tts_results: List[Dict]) -> List[Dict]:
        """å¹¶è¡Œæå–æ‰€æœ‰è§†é¢‘ç‰‡æ®µ"""
        print(f"\nâœ‚ï¸  å¹¶è¡Œæå–è§†é¢‘ç‰‡æ®µï¼ˆå¹¶å‘æ•°: {self.max_workers}ï¼‰...")
        
        # åŒ¹é… clip_selections å’Œ tts_results
        tasks = []
        for clip_info in clip_selections:
            index = clip_info['index']
            # æ‰¾åˆ°å¯¹åº”çš„ TTS ç»“æœ
            tts_result = next((t for t in tts_results if t['index'] == index), None)
            if tts_result:
                tasks.append((clip_info, tts_result['audio_file'], index))
        
        results = [None] * len(tasks)
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {
                executor.submit(self.extract_one, clip_info, audio_file, idx): idx - 1
                for clip_info, audio_file, idx in tasks
            }
            
            for future in as_completed(futures):
                result_index = futures[future]
                result = future.result()
                if result:
                    results[result_index] = result
        
        # è¿‡æ»¤ None
        results = [r for r in results if r is not None]
        
        cache_count = sum(1 for r in results if r.get('from_cache'))
        print(f"âœ… è§†é¢‘ç‰‡æ®µæå–å®Œæˆ: {len(results)} ä¸ªç‰‡æ®µï¼ˆ{cache_count} ä¸ªæ¥è‡ªç¼“å­˜ï¼‰\n")
        
        return results
    
    def _format_srt_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ– SRT æ—¶é—´"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


class VideoComposer:
    """è§†é¢‘åˆæˆå™¨"""
    
    @staticmethod
    def compose(clips: List[Dict], output_file: str):
        """åˆæˆæœ€ç»ˆè§†é¢‘"""
        import subprocess
        
        print(f"\nğŸ¬ åˆæˆæœ€ç»ˆè§†é¢‘...")
        
        # åˆ›å»ºåˆå¹¶åˆ—è¡¨
        temp_dir = os.path.dirname(output_file) or '.'
        concat_file = os.path.join(temp_dir, 'concat_list.txt')
        
        with open(concat_file, 'w', encoding='utf-8') as f:
            for clip in clips:
                f.write(f"file '{clip['video_file']}'\n")
        
        # åˆå¹¶
        cmd = [
            'ffmpeg', '-y', '-loglevel', 'warning',
            '-f', 'concat',
            '-safe', '0',
            '-i', concat_file,
            '-c', 'copy',
            output_file
        ]
        
        try:
            subprocess.run(cmd, check=True)
            print(f"âœ… æœ€ç»ˆè§†é¢‘å·²ä¿å­˜: {output_file}\n")
        except subprocess.CalledProcessError as e:
            print(f"âŒ åˆæˆå¤±è´¥: {e}\n")
        finally:
            if os.path.exists(concat_file):
                os.remove(concat_file)


def main():
    parser = argparse.ArgumentParser(
        description='å®Œæ•´è§†é¢‘ç”Ÿæˆæµç¨‹ï¼šæ–‡æ¡ˆ â†’ TTS â†’ ç‰‡æ®µé€‰æ‹© â†’ è§†é¢‘åˆæˆ'
    )
    
    parser.add_argument('script_file', help='æ–‡æ¡ˆè„šæœ¬æ–‡ä»¶ï¼ˆæ ¼å¼: [æ—¶é—´] [è¡Œå·] å†…å®¹ï¼‰')
    parser.add_argument('srt_file', help='åŸå§‹å­—å¹•æ–‡ä»¶ï¼ˆSRT æ ¼å¼ï¼‰')
    parser.add_argument('video_file', help='åŸå§‹è§†é¢‘æ–‡ä»¶')
    parser.add_argument('-o', '--output', default='final_output.mp4', help='è¾“å‡ºè§†é¢‘æ–‡ä»¶')
    
    parser.add_argument('--speaker', default='é¾™ç™½èŠ·', help='TTS è¯­éŸ³è§’è‰²ï¼ˆé»˜è®¤: é¾™ç™½èŠ·ï¼‰')
    parser.add_argument('--tts-workers', type=int, default=4, help='TTS å¹¶å‘æ•°ï¼ˆé»˜è®¤: 4ï¼‰')
    parser.add_argument('--clip-workers', type=int, default=3, help='ç‰‡æ®µé€‰æ‹©å¹¶å‘æ•°ï¼ˆé»˜è®¤: 3ï¼‰')
    parser.add_argument('--video-workers', type=int, default=3, help='è§†é¢‘æå–å¹¶å‘æ•°ï¼ˆé»˜è®¤: 3ï¼‰')
    
    parser.add_argument('--cache-dir', default='.cache', help='ç¼“å­˜ç›®å½•ï¼ˆé»˜è®¤: .cacheï¼‰')
    parser.add_argument('--force-clean', action='store_true', help='æ¸…ç†ç¼“å­˜åé‡æ–°ç”Ÿæˆ')
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("å®Œæ•´è§†é¢‘ç”Ÿæˆæµç¨‹")
    print("=" * 80)
    print(f"æ–‡æ¡ˆè„šæœ¬: {args.script_file}")
    print(f"åŸå§‹å­—å¹•: {args.srt_file}")
    print(f"åŸå§‹è§†é¢‘: {args.video_file}")
    print(f"è¾“å‡ºæ–‡ä»¶: {args.output}")
    print(f"TTS å¹¶å‘æ•°: {args.tts_workers}")
    print(f"ç‰‡æ®µé€‰æ‹©å¹¶å‘æ•°: {args.clip_workers}")
    print(f"è§†é¢‘æå–å¹¶å‘æ•°: {args.video_workers}")
    print(f"ç¼“å­˜ç›®å½•: {args.cache_dir}")
    print("=" * 80)
    
    # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
    cache_manager = CacheManager(args.cache_dir)
    if args.force_clean:
        print("\nğŸ—‘ï¸  æ¸…ç†ç¼“å­˜...")
        cache_manager.clear()
        print("âœ… ç¼“å­˜å·²æ¸…ç†\n")
    
    # Step 1: è§£ææ–‡æ¡ˆè„šæœ¬
    print("\nğŸ“„ Step 1: è§£ææ–‡æ¡ˆè„šæœ¬...")
    segments = ScriptParser.parse_script_file(args.script_file)
    print(f"âœ… å…±è§£æ {len(segments)} ä¸ªæ®µè½\n")
    
    # Step 2: è§£æåŸå§‹å­—å¹•
    print("ğŸ“„ Step 2: è§£æåŸå§‹å­—å¹•...")
    subtitles = SRTParser.parse_srt(args.srt_file)
    print(f"âœ… å…±è§£æ {len(subtitles)} æ¡å­—å¹•\n")
    
    # æ£€æŸ¥å¿…éœ€çš„ API keys
    deepseek_key = os.getenv("DEEPSEEK_API_KEY") or os.getenv("OPENAI_API_KEY")
    if not deepseek_key:
        print("\nâŒ é”™è¯¯: æœªæ‰¾åˆ° DEEPSEEK_API_KEY æˆ– OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("   è¯·è®¾ç½®ç¯å¢ƒå˜é‡: export DEEPSEEK_API_KEY=your_api_key")
        return 1
    
    bailian_key = os.getenv("BAILIAN_API_KEY")
    if not bailian_key:
        print("\nâŒ é”™è¯¯: æœªæ‰¾åˆ° BAILIAN_API_KEY ç¯å¢ƒå˜é‡")
        print("   è¯·è®¾ç½®ç¯å¢ƒå˜é‡: export BAILIAN_API_KEY=your_api_key")
        return 1
    
    # Step 3: å¹¶è¡Œç”Ÿæˆ TTS éŸ³é¢‘
    tts_generator = ParallelTTSGenerator(
        cache_manager, args.speaker, max_workers=args.tts_workers
    )
    tts_results = tts_generator.generate_all(segments)
    
    # Step 4: å¹¶è¡Œé€‰æ‹©è§†é¢‘ç‰‡æ®µ
    clip_selector = ParallelClipSelector(
        cache_manager, subtitles, max_workers=args.clip_workers
    )
    clip_selections = clip_selector.select_all(tts_results)
    
    # Step 5: å¹¶è¡Œæå–è§†é¢‘ç‰‡æ®µ
    video_clipper = ParallelVideoClipper(
        cache_manager, args.video_file, max_workers=args.video_workers
    )
    video_clips = video_clipper.extract_all(clip_selections, tts_results)
    
    # Step 6: åˆæˆæœ€ç»ˆè§†é¢‘
    VideoComposer.compose(video_clips, args.output)
    
    print("=" * 80)
    print("âœ… å…¨éƒ¨å®Œæˆï¼")
    print("=" * 80)


if __name__ == "__main__":
    import sys
    sys.exit(main())
