#!/usr/bin/env python3
"""
å®Œæ•´è§†é¢‘ç”Ÿæˆæµç¨‹ V2ï¼šæ”¯æŒV2æ ¼å¼æ–‡æ¡ˆï¼ˆè¿ç»­æ–‡æœ¬+åµŒå…¥è¡Œå·æ ‡è®°ï¼‰
1. è§£æ V2 æ ¼å¼æ–‡æ¡ˆï¼ˆæ–‡æœ¬å†…å®¹[è¡Œå·]...ï¼‰
2. å¹¶è¡Œç”Ÿæˆ TTS é…éŸ³ï¼ˆç¼“å­˜ï¼‰
3. å¹¶è¡Œè°ƒç”¨ DeepSeek ç»†åŒ–è§†é¢‘ç‰‡æ®µé€‰æ‹©ï¼ˆç¼“å­˜ï¼‰
4. å¹¶è¡Œæå–è§†é¢‘ç‰‡æ®µå¹¶æ·»åŠ é…éŸ³+å­—å¹•ï¼ˆç¼“å­˜ï¼‰
5. åˆæˆæœ€ç»ˆè§†é¢‘
"""

import os
import json
import re
import hashlib
import argparse
import shutil
import time
from pathlib import Path
from typing import List, Dict, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from openai import OpenAI

# å¯¼å…¥ç°æœ‰æ¨¡å—
from video_compressor import SRTParser, VideoClipFinder
from generate_tts import parse_script as parse_tts_script
from tts_client import CosyVoiceClient
from config.cosyvoice_config import CosyVoiceConfig


class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir: str = ".cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
        # å­ç›®å½•
        self.tts_cache_dir = self.cache_dir / "tts"
        self.clip_cache_dir = self.cache_dir / "clips"
        self.meta_cache_dir = self.cache_dir / "meta"
        
        for d in [self.tts_cache_dir, self.clip_cache_dir, self.meta_cache_dir]:
            d.mkdir(exist_ok=True)
    
    def get_hash(self, content: str) -> str:
        """ç”Ÿæˆå†…å®¹å“ˆå¸Œ"""
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def get_tts_cache_path(self, text: str, speaker: str) -> Path:
        """è·å– TTS ç¼“å­˜è·¯å¾„"""
        cache_key = f"{speaker}:{text}"
        cache_hash = self.get_hash(cache_key)
        return self.tts_cache_dir / f"{cache_hash}.wav"
    
    def get_clip_cache_path(self, clip_hash: str) -> Path:
        """è·å–è§†é¢‘ç‰‡æ®µç¼“å­˜è·¯å¾„"""
        return self.clip_cache_dir / f"{clip_hash}.mp4"
    
    def get_meta_cache_path(self, meta_type: str, key: str) -> Path:
        """è·å–å…ƒæ•°æ®ç¼“å­˜è·¯å¾„"""
        cache_hash = self.get_hash(key)
        return self.meta_cache_dir / f"{meta_type}_{cache_hash}.json"
    
    def save_json(self, path: Path, data: dict):
        """ä¿å­˜ JSON æ•°æ®"""
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def load_json(self, path: Path) -> dict:
        """åŠ è½½ JSON æ•°æ®"""
        if not path.exists():
            return None
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def clear(self):
        """æ¸…ç†æ‰€æœ‰ç¼“å­˜"""
        shutil.rmtree(self.cache_dir)
        self.__init__(str(self.cache_dir))


class ScriptParserV2:
    """V2 æ–‡æ¡ˆè„šæœ¬è§£æå™¨ - æ”¯æŒè¿ç»­æ–‡æœ¬+åµŒå…¥è¡Œå·æ ‡è®°
    
    æ ¼å¼: è¿ç»­æ–‡æœ¬å†…å®¹[è¡Œå·èŒƒå›´]æ›´å¤šæ–‡æœ¬[è¡Œå·èŒƒå›´]...
    ç¤ºä¾‹: æ€ªç›—åŸºå¾·[11-15]å‘å‡ºé¢„å‘Šä¿¡ï¼Œè¦å·æ–§æ±Ÿå®¶[16-20]çš„ä¸¤æŠŠè‚‹å·®åˆ€[21-25]...
    """
    
    @staticmethod
    def parse_script_file(script_file: str, chunk_words: int = 30) -> List[Dict]:
        """
        è§£æ V2 æ ¼å¼æ–‡æ¡ˆè„šæœ¬æ–‡ä»¶ - æŒ‰å¥å·å’Œæ¢è¡Œåˆ†å‰²
        
        Args:
            script_file: æ–‡æ¡ˆæ–‡ä»¶è·¯å¾„
            chunk_words: æœªä½¿ç”¨ï¼ˆä¿ç•™å‚æ•°å…¼å®¹æ€§ï¼‰ï¼Œå®é™…æŒ‰å¥å·/æ¢è¡Œåˆ†å‰²
            
        Returns:
            [{'text': '...', 'line_ranges': [[1,5], [6,10]], 'keywords': [...]}]
        """
        with open(script_file, 'r', encoding='utf-8') as f:
            content = f.read().strip()
        
        # å…ˆæŒ‰æ®µè½åˆ†å‰²ï¼ˆè¿ç»­ä¸¤ä¸ªæ¢è¡Œç¬¦ï¼‰
        paragraphs = re.split(r'\n\s*\n', content)
        
        segments = []
        
        for paragraph in paragraphs:
            # è·³è¿‡ç©ºæ®µè½
            if not paragraph.strip():
                continue
            
            # æå–æ®µè½ä¸­çš„æ‰€æœ‰å…³é”®è¯å’Œè¡Œå·æ ‡è®°
            # æ ¼å¼: å…³é”®è¯[è¡Œå·èŒƒå›´]
            pattern = r'([^[\]]+?)\[(\d+)-(\d+)\]'
            
            # å°†æ®µè½åˆ†å‰²æˆå¸¦è¡Œå·æ ‡è®°çš„ç‰‡æ®µ
            annotated_segments = []
            
            for match in re.finditer(pattern, paragraph):
                keyword = match.group(1).strip()
                line_start = int(match.group(2))
                line_end = int(match.group(3))
                
                if keyword:
                    annotated_segments.append({
                        'text': keyword,
                        'line_range': [line_start, line_end]
                    })
            
            # æŒ‰å¥å·åˆ†å‰²æ®µè½å†…çš„æ–‡æœ¬
            current_text = ""
            current_line_ranges = []
            
            for seg in annotated_segments:
                current_text += seg['text']
                current_line_ranges.append(seg['line_range'])
                
                # æ£€æŸ¥æ˜¯å¦é‡åˆ°å¥å·ï¼ˆä¸­æ–‡æˆ–è‹±æ–‡ï¼‰
                if current_text.rstrip().endswith(('ã€‚', '.', 'ï¼', '!', 'ï¼Ÿ', '?')):
                    if current_text.strip() and current_line_ranges:
                        segments.append({
                            'text': current_text.strip(),
                            'line_ranges': current_line_ranges.copy(),
                            'keywords': [s['text'] for s in annotated_segments[:len(current_line_ranges)]],
                            'line_range': [
                                min(r[0] for r in current_line_ranges),
                                max(r[1] for r in current_line_ranges)
                            ]
                        })
                    
                    # é‡ç½®
                    current_text = ""
                    current_line_ranges = []
            
            # æ·»åŠ æ®µè½æœ€åä¸€ä¸ªç‰‡æ®µï¼ˆå¦‚æœæ²¡æœ‰ä»¥å¥å·ç»“å°¾ï¼‰
            if current_text.strip() and current_line_ranges:
                segments.append({
                    'text': current_text.strip(),
                    'line_ranges': current_line_ranges.copy(),
                    'keywords': [s['text'] for s in annotated_segments[:len(current_line_ranges)]],
                    'line_range': [
                        min(r[0] for r in current_line_ranges),
                        max(r[1] for r in current_line_ranges)
                    ]
                })
        
        return segments


class ParallelTTSGenerator:
    """å¹¶è¡Œ TTS ç”Ÿæˆå™¨ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    
    def __init__(self, cache_manager: CacheManager, speaker_id: str = "é¾™ç™½èŠ", 
                 api_key: str = None, max_workers: int = 4):
        self.cache_manager = cache_manager
        self.speaker_id = speaker_id
        self.max_workers = max_workers
        
        # ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è·å– API key
        bailian_key = api_key or os.getenv("BAILIAN_API_KEY")
        if not bailian_key:
            raise ValueError(
                "BAILIAN_API_KEY is required for TTS generation. "
                "Please set the BAILIAN_API_KEY environment variable or pass --api-key argument."
            )
        
        # åˆå§‹åŒ– TTS å®¢æˆ·ç«¯
        config = CosyVoiceConfig(
            api_key=bailian_key,
            speaker_id=speaker_id,
            output_dir=str(cache_manager.tts_cache_dir)
        )
        self.tts_client = CosyVoiceClient(config)
    
    def generate_one(self, segment: Dict, index: int) -> Dict:
        """ç”Ÿæˆå•ä¸ª TTS éŸ³é¢‘ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        text = segment['text']
        
        # æ£€æŸ¥ç¼“å­˜
        cache_path = self.cache_manager.get_tts_cache_path(text, self.speaker_id)
        
        if cache_path.exists():
            print(f"  [{index}] âœ“ ä½¿ç”¨ç¼“å­˜ TTS: {cache_path.name}")
            return {
                'index': index,
                'audio_file': str(cache_path),
                'text': text,
                'line_range': segment['line_range'],
                'from_cache': True
            }
        
        # ç”Ÿæˆ TTSï¼ˆå¸¦é‡è¯•é€»è¾‘ï¼‰
        max_retries = 3
        retry_delay = 2  # ç§’
        
        for attempt in range(1, max_retries + 1):
            try:
                if attempt > 1:
                    print(f"  [{index}] ğŸ”„ é‡è¯• {attempt}/{max_retries}...")
                    time.sleep(retry_delay)
                
                print(f"  [{index}] ğŸ¤ ç”Ÿæˆ TTS: {text[:40]}...")
                result = self.tts_client.synthesize(text, str(cache_path))
                
                return {
                    'index': index,
                    'audio_file': str(cache_path),
                    'text': text,
                    'line_range': segment['line_range'],
                    'from_cache': False
                }
            except Exception as e:
                if attempt == max_retries:
                    print(f"  [{index}] âŒ TTS ç”Ÿæˆå¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰: {e}")
                    return None
                else:
                    print(f"  [{index}] âš ï¸  TTS å¤±è´¥: {e}")
        
        return None
    
    def generate_all(self, segments: List[Dict]) -> List[Dict]:
        """å¹¶è¡Œç”Ÿæˆæ‰€æœ‰ TTS éŸ³é¢‘"""
        print(f"\nğŸ¤ å¹¶è¡Œç”Ÿæˆ TTS éŸ³é¢‘ï¼ˆå¹¶å‘æ•°: {self.max_workers}ï¼‰...")
        
        results = [None] * len(segments)
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {
                executor.submit(self.generate_one, seg, i): i 
                for i, seg in enumerate(segments, 1)
            }
            
            for future in as_completed(futures):
                result = future.result()
                if result:
                    results[result['index'] - 1] = result
        
        # è¿‡æ»¤ None
        results = [r for r in results if r is not None]
        
        cache_count = sum(1 for r in results if r.get('from_cache'))
        print(f"âœ… TTS ç”Ÿæˆå®Œæˆ: {len(results)} ä¸ªéŸ³é¢‘ï¼ˆ{cache_count} ä¸ªæ¥è‡ªç¼“å­˜ï¼‰\n")
        
        return results


class ParallelClipSelector:
    """å¹¶è¡Œè§†é¢‘ç‰‡æ®µé€‰æ‹©å™¨ï¼ˆä½¿ç”¨ DeepSeek ç»†åŒ–ï¼‰"""
    
    def __init__(self, cache_manager: CacheManager, subtitles: List[Dict], 
                 api_key: str = None, max_workers: int = 3):
        self.cache_manager = cache_manager
        self.subtitles = subtitles
        self.max_workers = max_workers
        # ä»ç¯å¢ƒå˜é‡æˆ–å‚æ•°è·å– API key
        deepseek_key = api_key or os.getenv("DEEPSEEK_API_KEY") or os.getenv("OPENAI_API_KEY")
        self.clip_finder = VideoClipFinder(deepseek_key)
    
    def select_one(self, segment: Dict, index: int, audio_file: str = None) -> Dict:
        """
        ä¸ºå•ä¸ªç‰‡æ®µé€‰æ‹©æœ€ä½³è§†é¢‘ç‰‡æ®µï¼ˆå¸¦ç¼“å­˜ï¼‰
        ä½¿ç”¨ DeepSeek åœ¨æŒ‡å®šè¡Œå·èŒƒå›´å†…ç»†åŒ–é€‰æ‹©
        
        Args:
            segment: ç‰‡æ®µä¿¡æ¯
            index: ç‰‡æ®µç´¢å¼•
            audio_file: TTSéŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºè·å–çœŸå®æ—¶é•¿ï¼‰
        """
        text = segment['text']
        line_start, line_end = segment['line_range']
        
        # ç”Ÿæˆç¼“å­˜é”®ï¼ˆV2ä¸ä¾èµ–å›ºå®šdurationï¼‰
        cache_key = f"v2:{line_start}-{line_end}:{text}"
        cache_path = self.cache_manager.get_meta_cache_path("clip_selection", cache_key)
        
        # æ£€æŸ¥ç¼“å­˜
        cached_result = self.cache_manager.load_json(cache_path)
        if cached_result:
            print(f"  [{index}] âœ“ ä½¿ç”¨ç¼“å­˜ç‰‡æ®µé€‰æ‹©: [{line_start}-{line_end}]")
            cached_result['index'] = index
            return cached_result
        
        # è·å–çœŸå®çš„TTSéŸ³é¢‘æ—¶é•¿
        import subprocess
        actual_duration = len(text) / 6.0  # é»˜è®¤é¢„ä¼°
        
        if audio_file and os.path.exists(audio_file):
            try:
                # ä½¿ç”¨ffprobeè·å–éŸ³é¢‘æ—¶é•¿
                result = subprocess.run(
                    ['ffprobe', '-v', 'error', '-show_entries', 'format=duration',
                     '-of', 'default=noprint_wrappers=1:nokey=1', audio_file],
                    capture_output=True, text=True, check=True
                )
                actual_duration = float(result.stdout.strip())
                print(f"  [{index}] ğŸµ çœŸå®éŸ³é¢‘æ—¶é•¿: {actual_duration:.2f}s")
            except:
                print(f"  [{index}] âš ï¸  æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿ï¼Œä½¿ç”¨é¢„ä¼°å€¼: {actual_duration:.2f}s")
        
        # è°ƒç”¨ DeepSeek é€‰æ‹©ç‰‡æ®µ
        print(f"  [{index}] ğŸ¤– DeepSeek é€‰æ‹©ç‰‡æ®µ: [{line_start}-{line_end}] {text[:40]}...")
        
        clip_info = self.clip_finder.find_best_clip(
            text, self.subtitles, line_start, line_end, actual_duration
        )
        
        if not clip_info:
            print(f"  [{index}] \033[31mâœ— æ— åŒ¹é…\033[0m æœªæ‰¾åˆ°åˆé€‚ç‰‡æ®µ")
            return None
        
        # æ˜¾ç¤ºè´¨é‡è¯„åˆ†
        quality_score = clip_info.get('quality_score', 0)
        match_level = clip_info.get('match_level', 'none')
        
        # æ ¹æ®è´¨é‡ç­‰çº§æ˜¾ç¤ºä¸åŒé¢œè‰²
        if match_level == 'excellent':
            color = '\033[32m'  # ç»¿è‰²
            icon = 'âœ“ ä¼˜ç§€'
        elif match_level == 'good':
            color = '\033[36m'  # é’è‰²
            icon = 'âœ“ è‰¯å¥½'
        elif match_level == 'acceptable':
            color = '\033[33m'  # é»„è‰²
            icon = 'âš  å¯æ¥å—'
        elif match_level == 'poor':
            color = '\033[38;5;208m'  # æ©™è‰²
            icon = 'âš  è´¨é‡è¾ƒå·®'
        else:
            color = '\033[31m'  # çº¢è‰²
            icon = 'âœ— æ— åŒ¹é…'
        
        print(f"  [{index}] {color}{icon}\033[0m è´¨é‡è¯„åˆ†: {quality_score}/100")
        
        # æ·»åŠ å…ƒæ•°æ®
        clip_info['index'] = index
        clip_info['text'] = text
        
        # ä¿å­˜ç¼“å­˜
        self.cache_manager.save_json(cache_path, clip_info)
        
        return clip_info
    
    def select_all(self, segments: List[Dict]) -> List[Dict]:
        """å¹¶è¡Œé€‰æ‹©æ‰€æœ‰è§†é¢‘ç‰‡æ®µ"""
        print(f"\nğŸ¤– å¹¶è¡Œé€‰æ‹©è§†é¢‘ç‰‡æ®µï¼ˆå¹¶å‘æ•°: {self.max_workers}ï¼‰...")
        
        results = [None] * len(segments)
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {
                executor.submit(self.select_one, seg, i): i 
                for i, seg in enumerate(segments, 1)
            }
            
            for future in as_completed(futures):
                result = future.result()
                if result:
                    results[result['index'] - 1] = result
        
        # è¿‡æ»¤ None
        results = [r for r in results if r is not None]
        
        print(f"âœ… ç‰‡æ®µé€‰æ‹©å®Œæˆ: {len(results)} ä¸ªç‰‡æ®µ\n")
        
        return results


class ParallelVideoClipper:
    """å¹¶è¡Œè§†é¢‘ç‰‡æ®µæå–å™¨ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    
    def __init__(self, cache_manager: CacheManager, original_video: str, 
                 max_workers: int = 3):
        self.cache_manager = cache_manager
        self.original_video = original_video
        self.max_workers = max_workers
    
    def extract_one(self, clip_info: Dict, audio_file: str, index: int) -> Dict:
        """æå–å•ä¸ªè§†é¢‘ç‰‡æ®µå¹¶æ·»åŠ é…éŸ³+å­—å¹•ï¼ˆå¸¦ç¼“å­˜ï¼Œæ”¯æŒå¤šç‰‡æ®µæ‹¼æ¥ï¼‰"""
        import subprocess
        import tempfile
        
        text = clip_info['text']
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå¤šç‰‡æ®µæ¨¡å¼
        is_multi_clip = clip_info.get('multi_clip', False)
        
        if is_multi_clip and 'clips' in clip_info:
            # å¤šç‰‡æ®µæ‹¼æ¥æ¨¡å¼
            return self._extract_multi_clips(clip_info, audio_file, index)
        else:
            # å•ç‰‡æ®µæ¨¡å¼
            start_time = clip_info['start_time']
            end_time = clip_info['end_time']
            duration = end_time - start_time
            
            return self._extract_single_clip(start_time, duration, text, audio_file, index)
    
    def _extract_multi_clips(self, clip_info: Dict, audio_file: str, index: int) -> Dict:
        """æå–å¹¶æ‹¼æ¥å¤šä¸ªè§†é¢‘ç‰‡æ®µ"""
        import subprocess
        import tempfile
        
        text = clip_info['text']
        clips = clip_info['clips']
        
        # ç”Ÿæˆç¼“å­˜é”®ï¼ˆåŸºäºæ‰€æœ‰ç‰‡æ®µä¿¡æ¯ï¼‰
        clips_key = ','.join([f"{c['start_time']:.2f}-{c['end_time']:.2f}" for c in clips])
        cache_key = f"multi:{clips_key}:{audio_file}:{text}"
        cache_hash = self.cache_manager.get_hash(cache_key)
        cache_path = self.cache_manager.get_clip_cache_path(cache_hash)
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_path.exists():
            print(f"  [{index}] âœ“ ä½¿ç”¨ç¼“å­˜å¤šç‰‡æ®µ: {cache_path.name}")
            return {
                'index': index,
                'video_file': str(cache_path),
                'audio_file': audio_file,
                'text': text,
                'from_cache': True
            }
        
        print(f"       â³ å¼€å§‹æ‹¼æ¥ {len(clips)} ä¸ªè§†é¢‘ç‰‡æ®µ...")
        
        # Step 1: æå–å„ä¸ªç‰‡æ®µåˆ°ä¸´æ—¶æ–‡ä»¶
        temp_clips = []
        for i, clip in enumerate(clips, 1):
            temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.mp4', delete=False)
            temp_file.close()
            
            cmd = [
                'ffmpeg', '-y', '-loglevel', 'error',
                '-ss', str(clip['start_time']),
                '-i', self.original_video,
                '-t', str(clip['duration']),
                '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '23',
                '-an',  # ä¸è¦éŸ³é¢‘ï¼Œç¨åç»Ÿä¸€æ·»åŠ 
                temp_file.name
            ]
            
            print(f"       æå–ç‰‡æ®µ{i}/{len(clips)}: {clip['start_time']:.1f}s-{clip['end_time']:.1f}s ({clip['duration']:.1f}s)")
            subprocess.run(cmd, check=True)
            temp_clips.append(temp_file.name)
        
        # Step 2: æ‹¼æ¥æ‰€æœ‰ç‰‡æ®µ
        concat_list = tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8')
        for clip_file in temp_clips:
            concat_list.write(f"file '{clip_file}'\n")
        concat_list.close()
        
        temp_concat = tempfile.NamedTemporaryFile(mode='w', suffix='.mp4', delete=False)
        temp_concat.close()
        
        print(f"       æ‹¼æ¥ {len(temp_clips)} ä¸ªç‰‡æ®µ...")
        cmd = [
            'ffmpeg', '-y', '-loglevel', 'error',
            '-f', 'concat', '-safe', '0',
            '-i', concat_list.name,
            '-c', 'copy',
            temp_concat.name
        ]
        subprocess.run(cmd, check=True)
        
        # Step 3: æ·»åŠ å­—å¹•å’Œé…éŸ³
        result = self._add_subtitles_and_audio(temp_concat.name, text, audio_file, cache_path, index)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for temp_file in temp_clips:
            try:
                os.unlink(temp_file)
            except:
                pass
        try:
            os.unlink(concat_list.name)
            os.unlink(temp_concat.name)
        except:
            pass
        
        return result
    
    def _extract_single_clip(self, start_time: float, duration: float, text: str, 
                            audio_file: str, index: int) -> Dict:
        """æå–å•ä¸ªè§†é¢‘ç‰‡æ®µ"""
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = f"{start_time:.2f}-{duration:.2f}:{audio_file}:{text}"
        cache_hash = self.cache_manager.get_hash(cache_key)
        cache_path = self.cache_manager.get_clip_cache_path(cache_hash)
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_path.exists():
            print(f"  [{index}] âœ“ ä½¿ç”¨ç¼“å­˜ç‰‡æ®µ: {cache_path.name}")
            return {
                'index': index,
                'video_file': str(cache_path),
                'audio_file': audio_file,
                'text': text,
                'from_cache': True
            }
        
        print(f"       â³ å¼€å§‹å‹åˆ¶è§†é¢‘ç‰‡æ®µ...")
        
        # æå–è§†é¢‘ç‰‡æ®µåˆ°ä¸´æ—¶æ–‡ä»¶
        import subprocess
        import tempfile
        
        temp_video = tempfile.NamedTemporaryFile(mode='w', suffix='.mp4', delete=False)
        temp_video.close()
        
        cmd = [
            'ffmpeg', '-y', '-loglevel', 'error',
            '-ss', str(start_time),
            '-i', self.original_video,
            '-t', str(duration),
            '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '23',
            '-an',
            temp_video.name
        ]
        subprocess.run(cmd, check=True)
        
        # æ·»åŠ å­—å¹•å’Œé…éŸ³
        result = self._add_subtitles_and_audio(temp_video.name, text, audio_file, cache_path, index)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.unlink(temp_video.name)
        except:
            pass
        
        return result
    
    def _add_subtitles_and_audio(self, video_file: str, text: str, audio_file: str, 
                                 output_path: Path, index: int) -> Dict:
        """ä¸ºè§†é¢‘æ·»åŠ å­—å¹•å’Œé…éŸ³"""
        import subprocess
        import tempfile
        import re
        
        # è·å–è§†é¢‘æ—¶é•¿
        result = subprocess.run(
            ['ffprobe', '-v', 'error', '-show_entries', 'format=duration',
             '-of', 'default=noprint_wrappers=1:nokey=1', video_file],
            capture_output=True, text=True, check=True
        )
        video_duration = float(result.stdout.strip())
        
        # è·å–éŸ³é¢‘æ—¶é•¿
        result = subprocess.run(
            ['ffprobe', '-v', 'error', '-show_entries', 'format=duration',
             '-of', 'default=noprint_wrappers=1:nokey=1', audio_file],
            capture_output=True, text=True, check=True
        )
        audio_duration = float(result.stdout.strip())
        
        # ğŸš¨ ä¸¥æ ¼æ£€æŸ¥ï¼šè§†é¢‘æ—¶é•¿å¿…é¡»ä¸éŸ³é¢‘æ—¶é•¿åŒ¹é…ï¼ˆå…è®¸è¯¯å·®1ç§’ï¼‰
        time_diff = abs(video_duration - audio_duration)
        if time_diff > 1.0:
            error_msg = f"\n{'='*80}\nâŒ è‡´å‘½é”™è¯¯ï¼šè§†é¢‘æ—¶é•¿ä¸éŸ³é¢‘æ—¶é•¿ä¸åŒ¹é…ï¼\n"
            error_msg += f"   è§†é¢‘æ—¶é•¿: {video_duration:.2f}s\n"
            error_msg += f"   éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f}s\n"
            error_msg += f"   å·®è·: {time_diff:.2f}s (å…è®¸æœ€å¤§1.0s)\n"
            error_msg += f"   æ–‡æœ¬: {text[:100]}...\n"
            error_msg += f"{'='*80}\n"
            print(error_msg)
            raise ValueError(f"è§†é¢‘æ—¶é•¿ {video_duration:.2f}s ä¸éŸ³é¢‘æ—¶é•¿ {audio_duration:.2f}s å·®è·è¿‡å¤§ ({time_diff:.2f}s > 1.0s)")
        
        print(f"       âœ“ æ—¶é•¿éªŒè¯é€šè¿‡: è§†é¢‘ {video_duration:.2f}s â‰ˆ éŸ³é¢‘ {audio_duration:.2f}s (å·®è· {time_diff:.2f}s)")
        
        # ä½¿ç”¨éŸ³é¢‘æ—¶é•¿ä½œä¸ºåŸºå‡†ï¼ˆæ›´å‡†ç¡®ï¼‰
        duration = audio_duration
        
        # æ¸…ç†å­—å¹•æ–‡æœ¬ï¼šå»æ‰å¼€å¤´çš„æ ‡ç‚¹ç¬¦å·
        clean_text = text.lstrip('ï¼Œã€‚,. \t')
        
        # åˆ›å»ºä¸´æ—¶å­—å¹•æ–‡ä»¶ - æŒ‰æ ‡ç‚¹ç¬¦å·è‡ªç„¶æ–­å¥
        srt_file = tempfile.NamedTemporaryFile(mode='w', suffix='.srt', delete=False, encoding='utf-8')
        
        # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²å­—å¹•ï¼ˆé€—å·ã€å¥å·ã€æ„Ÿå¹å·ã€é—®å·ï¼‰
        segments = re.split(r'([ï¼Œã€‚,!ï¼?ï¼Ÿ])', clean_text)
        
        # é‡ç»„ï¼šå°†æ ‡ç‚¹ç¬¦å·é™„åŠ åˆ°å‰ä¸€ä¸ªç‰‡æ®µ
        merged_segments = []
        for i in range(0, len(segments), 2):
            if i < len(segments):
                seg = segments[i]
                if i + 1 < len(segments):
                    seg += segments[i + 1]  # é™„åŠ æ ‡ç‚¹
                if seg.strip():  # è·³è¿‡ç©ºç‰‡æ®µ
                    merged_segments.append(seg)
        
        if not merged_segments:  # å¦‚æœæ²¡æœ‰æ ‡ç‚¹ï¼Œæ•´æ®µä½œä¸ºä¸€ä¸ªå­—å¹•
            merged_segments = [clean_text]
        
        # è®¡ç®—æ¯æ®µçš„æ—¶é—´ï¼ˆæŒ‰å­—æ•°æ¯”ä¾‹åˆ†é…ï¼‰
        total_chars = sum(len(s) for s in merged_segments)
        
        # ç”Ÿæˆ SRT å†…å®¹
        srt_content = []
        current_time = 0.0
        for idx, seg in enumerate(merged_segments):
            seg_duration = (len(seg) / total_chars) * duration
            start = current_time
            end = current_time + seg_duration
            srt_content.append(f"{idx+1}\n{self._format_srt_time(start)} --> {self._format_srt_time(end)}\n{seg}\n")
            current_time = end
        
        srt_file.write('\n'.join(srt_content))
        srt_file.close()
        
        print(f"       å­—å¹•æ–‡ä»¶: {srt_file.name}")
        print(f"       å­—å¹•åˆ†æ®µ: {len(merged_segments)} æ®µï¼ˆæŒ‰æ ‡ç‚¹ç¬¦å·è‡ªç„¶æ–­å¥ï¼‰")
        print(f"       å­—å¹•å†…å®¹: {clean_text[:50]}...")
        
        # FFmpeg å‘½ä»¤ï¼šæ·»åŠ é…éŸ³ + çƒ§å½•å­—å¹• + ç¼©æ”¾
        cmd = [
            'ffmpeg', '-y', '-loglevel', 'error',
            '-i', video_file,
            '-i', audio_file,
            '-filter_complex',
            f"[0:v]scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2,subtitles={srt_file.name}:force_style='Fontsize=8,PrimaryColour=&H00FFFFFF,OutlineColour=&H00000000,Outline=2,Shadow=1,MarginV=40,Alignment=2'[vout]",
            '-map', '[vout]',
            '-map', '1:a',
            '-c:v', 'libx264',
            '-preset', 'ultrafast',
            '-crf', '23',
            '-c:a', 'aac',
            '-b:a', '128k',
            '-ar', '44100',
            '-ac', '2',
            str(output_path)
        ]
        
        try:
            print(f"       ğŸ¬ FFmpeg æ·»åŠ å­—å¹•å’Œé…éŸ³...")
            subprocess.run(cmd, check=True, timeout=120)
            print(f"       âœ… å‹åˆ¶æˆåŠŸ: {output_path.name}")
        except Exception as e:
            print(f"       âŒ å‹åˆ¶å¤±è´¥: {e}")
            return None
        finally:
            try:
                os.unlink(srt_file.name)
            except:
                pass
        
        return {
            'index': index,
            'video_file': str(output_path),
            'audio_file': audio_file,
            'text': text,
            'from_cache': False
        }
    
    def extract_all(self, clip_selections: List[Dict], tts_results: List[Dict]) -> List[Dict]:
        """é¡ºåºæå–æ‰€æœ‰è§†é¢‘ç‰‡æ®µï¼ˆé€ä¸ªå¯¹é½å’Œå‹åˆ¶ï¼‰"""
        print(f"\nâœ‚ï¸  é¡ºåºæå–è§†é¢‘ç‰‡æ®µï¼ˆé€ä¸ªå¤„ç†ï¼‰...")
        print("=" * 80)
        
        results = []
        
        # æŒ‰é¡ºåºå¤„ç†æ¯ä¸ªç‰‡æ®µ
        for clip_info in clip_selections:
            index = clip_info['index']
            
            # æ‰¾åˆ°å¯¹åº”çš„ TTS ç»“æœ
            tts_result = next((t for t in tts_results if t['index'] == index), None)
            if not tts_result:
                print(f"  [{index}] âš ï¸  è·³è¿‡: æœªæ‰¾åˆ°å¯¹åº”çš„ TTS éŸ³é¢‘")
                continue
            
            audio_file = tts_result['audio_file']
            
            # å¤„ç†å•ä¸ªç‰‡æ®µ
            print(f"\n  [{index}] ğŸ“ å¼€å§‹å¯¹é½å­—å¹•...")
            print(f"       æ–‡æœ¬: {clip_info['text'][:60]}...")
            print(f"       æ—¶é—´: {clip_info['start_time']:.1f}s - {clip_info['end_time']:.1f}s")
            print(f"       éŸ³é¢‘: {audio_file}")
            
            result = self.extract_one(clip_info, audio_file, index)
            
            if result:
                results.append(result)
                print(f"  [{index}] âœ… å‹åˆ¶å®Œæˆ!")
                print(f"       è¾“å‡ºè·¯å¾„: {result['video_file']}")
                print(f"       æ–‡ä»¶å¤§å°: {os.path.getsize(result['video_file']) / (1024*1024):.2f} MB")
            else:
                print(f"  [{index}] âŒ å¤„ç†å¤±è´¥")
            
            print("-" * 80)
        
        cache_count = sum(1 for r in results if r.get('from_cache'))
        print(f"\nâœ… è§†é¢‘ç‰‡æ®µæå–å®Œæˆ: {len(results)} ä¸ªç‰‡æ®µï¼ˆ{cache_count} ä¸ªæ¥è‡ªç¼“å­˜ï¼‰\n")
        
        return results
    
    def _format_srt_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ– SRT æ—¶é—´"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


class VideoComposer:
    """è§†é¢‘åˆæˆå™¨"""
    
    @staticmethod
    def compose(clips: List[Dict], output_file: str):
        """åˆæˆæœ€ç»ˆè§†é¢‘"""
        import subprocess
        
        print(f"\nğŸ¬ åˆæˆæœ€ç»ˆè§†é¢‘...")
        
        # åˆ›å»ºåˆå¹¶åˆ—è¡¨
        temp_dir = os.path.dirname(output_file) or '.'
        concat_file = os.path.join(temp_dir, 'concat_list.txt')
        
        with open(concat_file, 'w', encoding='utf-8') as f:
            for clip in clips:
                f.write(f"file '{clip['video_file']}'\n")
        
        # åˆå¹¶ï¼ˆé‡æ–°ç¼–ç éŸ³é¢‘ç¡®ä¿å…¼å®¹æ€§ï¼‰
        cmd = [
            'ffmpeg', '-y', '-loglevel', 'warning',
            '-f', 'concat',
            '-safe', '0',
            '-i', concat_file,
            '-c:v', 'copy',  # è§†é¢‘ç›´æ¥å¤åˆ¶
            '-c:a', 'aac',  # éŸ³é¢‘é‡æ–°ç¼–ç ä¸ºAAC
            '-b:a', '192k',  # æé«˜éŸ³é¢‘æ¯”ç‰¹ç‡
            '-ar', '44100',  # é‡‡æ ·ç‡44.1kHz
            '-ac', '2',  # ç«‹ä½“å£°
            output_file
        ]
        
        try:
            subprocess.run(cmd, check=True)
            print(f"âœ… æœ€ç»ˆè§†é¢‘å·²ä¿å­˜: {output_file}\n")
        except subprocess.CalledProcessError as e:
            print(f"âŒ åˆæˆå¤±è´¥: {e}\n")
        finally:
            if os.path.exists(concat_file):
                os.remove(concat_file)


def main():
    parser = argparse.ArgumentParser(
        description='å®Œæ•´è§†é¢‘ç”Ÿæˆæµç¨‹ V2ï¼šæ”¯æŒè¿ç»­æ–‡æ¡ˆ+åµŒå…¥è¡Œå·æ ‡è®°'
    )
    
    parser.add_argument('script_file', help='V2æ–‡æ¡ˆè„šæœ¬æ–‡ä»¶ï¼ˆæ ¼å¼: æ–‡æœ¬[è¡Œå·]æ–‡æœ¬[è¡Œå·]...ï¼‰')
    parser.add_argument('srt_file', help='åŸå§‹å­—å¹•æ–‡ä»¶ï¼ˆSRT æ ¼å¼ï¼‰')
    parser.add_argument('video_file', help='åŸå§‹è§†é¢‘æ–‡ä»¶')
    parser.add_argument('-o', '--output', default='final_output_v2.mp4', help='è¾“å‡ºè§†é¢‘æ–‡ä»¶')
    
    parser.add_argument('--chunk-words', type=int, default=30, 
                       help='æ¯ä¸ªç‰‡æ®µçš„å­—æ•°ï¼ˆé»˜è®¤30å­—ï¼Œçº¦6-8ç§’TTSï¼‰')
    parser.add_argument('--speaker', default='é¾™ç™½èŠ·', help='TTS è¯­éŸ³è§’è‰²ï¼ˆé»˜è®¤: é¾™ç™½èŠ·ï¼‰')
    parser.add_argument('--tts-workers', type=int, default=4, help='TTS å¹¶å‘æ•°ï¼ˆé»˜è®¤: 4ï¼‰')
    parser.add_argument('--clip-workers', type=int, default=3, help='ç‰‡æ®µé€‰æ‹©å¹¶å‘æ•°ï¼ˆé»˜è®¤: 3ï¼‰')
    parser.add_argument('--video-workers', type=int, default=3, help='è§†é¢‘æå–å¹¶å‘æ•°ï¼ˆé»˜è®¤: 3ï¼‰')
    
    parser.add_argument('--cache-dir', default='.cache', help='ç¼“å­˜ç›®å½•ï¼ˆé»˜è®¤: .cacheï¼‰')
    parser.add_argument('--force-clean', action='store_true', help='æ¸…ç†ç¼“å­˜åé‡æ–°ç”Ÿæˆ')
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("å®Œæ•´è§†é¢‘ç”Ÿæˆæµç¨‹ V2 (è¿ç»­æ–‡æ¡ˆ+åµŒå…¥è¡Œå·)")
    print("=" * 80)
    print(f"æ–‡æ¡ˆè„šæœ¬: {args.script_file}")
    print(f"åŸå§‹å­—å¹•: {args.srt_file}")
    print(f"åŸå§‹è§†é¢‘: {args.video_file}")
    print(f"è¾“å‡ºæ–‡ä»¶: {args.output}")
    print(f"ç‰‡æ®µå­—æ•°: {args.chunk_words} å­—/ç‰‡æ®µ")
    print(f"TTS å¹¶å‘æ•°: {args.tts_workers}")
    print(f"ç‰‡æ®µé€‰æ‹©å¹¶å‘æ•°: {args.clip_workers}")
    print(f"è§†é¢‘æå–å¹¶å‘æ•°: {args.video_workers}")
    print(f"ç¼“å­˜ç›®å½•: {args.cache_dir}")
    print("=" * 80)
    
    # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
    cache_manager = CacheManager(args.cache_dir)
    if args.force_clean:
        print("\nğŸ—‘ï¸  æ¸…ç†ç¼“å­˜...")
        cache_manager.clear()
        print("âœ… ç¼“å­˜å·²æ¸…ç†\n")
    
    # Step 1: è§£æ V2 æ ¼å¼æ–‡æ¡ˆè„šæœ¬
    print("\nğŸ“„ Step 1: è§£æ V2 æ ¼å¼æ–‡æ¡ˆè„šæœ¬...")
    segments = ScriptParserV2.parse_script_file(args.script_file, args.chunk_words)
    print(f"âœ… å…±è§£æ {len(segments)} ä¸ªç‰‡æ®µ\n")
    
    # æ˜¾ç¤ºå‰3ä¸ªç‰‡æ®µé¢„è§ˆ
    print("é¢„è§ˆå‰3ä¸ªç‰‡æ®µ:")
    for i, seg in enumerate(segments[:3], 1):
        print(f"  [{i}] {seg['text'][:50]}... (è¡Œå·: {seg['line_range']})")
    if len(segments) > 3:
        print(f"  ... è¿˜æœ‰ {len(segments) - 3} ä¸ªç‰‡æ®µ")
    print()
    
    # Step 2: è§£æåŸå§‹å­—å¹•
    print("ğŸ“„ Step 2: è§£æåŸå§‹å­—å¹•...")
    subtitles = SRTParser.parse_srt(args.srt_file)
    print(f"âœ… å…±è§£æ {len(subtitles)} æ¡å­—å¹•\n")
    
    # æ£€æŸ¥å¿…éœ€çš„ API keysï¼ˆä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼ï¼‰
    deepseek_key = os.getenv("DEEPSEEK_API_KEY") or os.getenv("OPENAI_API_KEY") or "sk-b806e7ca03ab4a9cb12445a659349268"
    bailian_key = os.getenv("BAILIAN_API_KEY") or "sk-f0b5e3f543d64b0d8640888cb4327b74"
    
    # Step 3: æµæ°´çº¿å¤„ç† - TTS + ç‰‡æ®µé€‰æ‹© + è§†é¢‘å‹åˆ¶
    print("\nğŸ”„ æµæ°´çº¿å¤„ç†: TTS â†’ ç‰‡æ®µé€‰æ‹© â†’ è§†é¢‘å‹åˆ¶")
    print("=" * 80)
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    tts_generator = ParallelTTSGenerator(
        cache_manager, args.speaker, api_key=bailian_key, max_workers=1  # å•çº¿ç¨‹é¡ºåºå¤„ç†
    )
    clip_selector = ParallelClipSelector(
        cache_manager, subtitles, api_key=deepseek_key, max_workers=1
    )
    video_clipper = ParallelVideoClipper(
        cache_manager, args.video_file, max_workers=1
    )
    
    video_clips = []
    
    # é€ä¸ªå¤„ç†æ¯ä¸ªæ®µè½
    for i, segment in enumerate(segments, 1):
        print(f"\n{'='*80}")
        print(f"å¤„ç†ç¬¬ {i}/{len(segments)} ä¸ªç‰‡æ®µ")
        print(f"{'='*80}")
        
        # Step 3.1: ç”Ÿæˆ TTS
        print(f"  ğŸ¤ [{i}] ç”Ÿæˆ TTS: {segment['text'][:50]}...")
        tts_result = tts_generator.generate_one(segment, i)
        if not tts_result:
            print(f"  âŒ [{i}] TTS ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡")
            continue
        
        print(f"  âœ… [{i}] TTS å®Œæˆ: {tts_result['audio_file']}")
        
        # Step 3.2: é€‰æ‹©è§†é¢‘ç‰‡æ®µï¼ˆä¼ å…¥çœŸå®éŸ³é¢‘æ–‡ä»¶ï¼‰
        print(f"  ğŸ¤– [{i}] DeepSeek é€‰æ‹©ç‰‡æ®µ...")
        clip_selection = clip_selector.select_one(tts_result, i, audio_file=tts_result['audio_file'])
        if not clip_selection:
            print(f"  âŒ [{i}] ç‰‡æ®µé€‰æ‹©å¤±è´¥ï¼Œè·³è¿‡")
            continue
        
        print(f"  âœ… [{i}] ç‰‡æ®µé€‰æ‹©å®Œæˆ: [{clip_selection['start_time']:.1f}s - {clip_selection['end_time']:.1f}s]")
        
        # Step 3.3: ç«‹å³å‹åˆ¶è§†é¢‘
        print(f"  ğŸ“ [{i}] å¼€å§‹å¯¹é½å­—å¹•å¹¶å‹åˆ¶è§†é¢‘...")
        print(f"       æ–‡æœ¬: {clip_selection['text'][:60]}...")
        print(f"       æ—¶é—´: {clip_selection['start_time']:.1f}s - {clip_selection['end_time']:.1f}s")
        print(f"       éŸ³é¢‘: {tts_result['audio_file']}")
        
        video_clip = video_clipper.extract_one(clip_selection, tts_result['audio_file'], i)
        if video_clip:
            video_clips.append(video_clip)
            print(f"  âœ… [{i}] å‹åˆ¶å®Œæˆ!")
            print(f"       è¾“å‡ºè·¯å¾„: {video_clip['video_file']}")
            print(f"       æ–‡ä»¶å¤§å°: {os.path.getsize(video_clip['video_file']) / (1024*1024):.2f} MB")
        else:
            print(f"  âŒ [{i}] è§†é¢‘å‹åˆ¶å¤±è´¥")
    
    print(f"\n{'='*80}")
    print(f"âœ… æ‰€æœ‰ç‰‡æ®µå¤„ç†å®Œæˆ: {len(video_clips)}/{len(segments)} ä¸ªæˆåŠŸ")
    print(f"{'='*80}\n")
    
    # Step 4: åˆæˆæœ€ç»ˆè§†é¢‘
    if video_clips:
        VideoComposer.compose(video_clips, args.output)
    else:
        print("âŒ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•è§†é¢‘ç‰‡æ®µï¼Œæ— æ³•åˆæˆæœ€ç»ˆè§†é¢‘")
    
    print("=" * 80)
    print("âœ… å…¨éƒ¨å®Œæˆï¼")
    print("=" * 80)


if __name__ == "__main__":
    import sys
    sys.exit(main())
