#!/usr/bin/env python3
"""
è§†é¢‘åˆæˆå™¨ - æ ¹æ® timeline.json å‰ªè¾‘è§†é¢‘ã€æ·»åŠ é…éŸ³å’Œå­—å¹•
"""

import os
import json
import re
import subprocess
from pathlib import Path
from typing import List, Dict, Tuple
from openai import OpenAI
from concurrent.futures import ThreadPoolExecutor, as_completed


class SRTParser:
    """SRT å­—å¹•è§£æå™¨"""
    
    @staticmethod
    def parse_srt(srt_file: str) -> List[Dict]:
        """
        è§£æ SRT å­—å¹•æ–‡ä»¶
        
        Returns:
            å­—å¹•åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å¹•åŒ…å« index, start_time, end_time, text
        """
        subtitles = []
        
        with open(srt_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åˆ†å‰²æ¯ä¸ªå­—å¹•å—
        blocks = re.split(r'\n\s*\n', content.strip())
        
        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) < 3:
                continue
            
            try:
                index = int(lines[0])
                time_line = lines[1]
                text = '\n'.join(lines[2:])
                
                # è§£ææ—¶é—´
                match = re.match(r'(\d{2}):(\d{2}):(\d{2}),(\d{3})\s*-->\s*(\d{2}):(\d{2}):(\d{2}),(\d{3})', time_line)
                if match:
                    start_h, start_m, start_s, start_ms = map(int, match.groups()[:4])
                    end_h, end_m, end_s, end_ms = map(int, match.groups()[4:])
                    
                    start_time = start_h * 3600 + start_m * 60 + start_s + start_ms / 1000
                    end_time = end_h * 3600 + end_m * 60 + end_s + end_ms / 1000
                    
                    subtitles.append({
                        'index': index,
                        'start_time': start_time,
                        'end_time': end_time,
                        'text': text
                    })
            except Exception as e:
                print(f"  âš  è§£æå­—å¹•å—å¤±è´¥: {e}")
                continue
        
        return subtitles
    
    @staticmethod
    def find_subtitle_by_line(subtitles: List[Dict], line_number: int) -> Dict:
        """
        æ ¹æ®è¡Œå·æŸ¥æ‰¾å­—å¹•ï¼ˆSRT ä¸­çš„ indexï¼‰
        """
        for sub in subtitles:
            if sub['index'] == line_number:
                return sub
        return None


class VideoClipFinder:
    """è§†é¢‘ç‰‡æ®µæŸ¥æ‰¾å™¨ - ä½¿ç”¨ DeepSeek LLM"""
    
    def __init__(self, api_key: str = "sk-b806e7ca03ab4a9cb12445a659349268"):
        self.client = OpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com/v1"
        )
    
    def find_best_clip(self, narration_text: str, subtitles: List[Dict], 
                      line_start: int, line_end: int, duration: float) -> Dict:
        """
        ä½¿ç”¨ LLM åœ¨æŒ‡å®šè¡Œå·èŒƒå›´å†…æ‰¾åˆ°æœ€åŒ¹é…çš„è§†é¢‘ç‰‡æ®µ
        
        Args:
            narration_text: æ—ç™½æ–‡æœ¬
            subtitles: åŸå§‹å­—å¹•åˆ—è¡¨
            line_start: èµ·å§‹è¡Œå·
            line_end: ç»“æŸè¡Œå·
            duration: éœ€è¦çš„ç‰‡æ®µæ—¶é•¿
            
        Returns:
            æœ€ä½³ç‰‡æ®µä¿¡æ¯ {start_time, end_time, confidence, reason}
        """
        # å¯¹é½è°ƒæ•´ï¼šå­—å¹•çš„å‰ä¸¤è¡Œä¸æ˜¯100%å¯¹åº”çš„ï¼Œæ‰€ä»¥éœ€è¦ -2
        line_start_adjusted = line_start
        line_end_adjusted = line_end
        
        # å¦‚æœè°ƒæ•´åè¡Œå·ä¸ºè´Ÿæ•°æˆ–0ï¼Œè¯´æ˜å¯¹åº”çš„æ˜¯å­—å¹•å‰ä¸¤è¡Œä¸å‡†ç¡®çš„éƒ¨åˆ†ï¼Œç›´æ¥è·³è¿‡
        if line_start_adjusted <= 0 or line_end_adjusted <= 0:
            print(f"  âš ï¸ è·³è¿‡ç‰‡æ®µï¼šè°ƒæ•´åè¡Œå·ä¸ºè´Ÿæ•° (åŸå§‹: [{line_start}-{line_end}] â†’ è°ƒæ•´å: [{line_start_adjusted}-{line_end_adjusted}])")
            print(f"     åŸå› ï¼šå­—å¹•å‰ä¸¤è¡Œä¸å¯¹åº”ï¼Œæ— æ³•å‡†ç¡®åŒ¹é…è§†é¢‘ç‰‡æ®µ")
            return None
        
        # æå–èŒƒå›´å†…çš„å­—å¹•
        range_subs = [s for s in subtitles if line_start_adjusted <= s['index'] <= line_end_adjusted]
        
        if not range_subs:
            print(f"  âš  è¡Œå·èŒƒå›´ [{line_start_adjusted}-{line_end_adjusted}] (åŸå§‹: [{line_start}-{line_end}], å·²è°ƒæ•´-2) å†…æ²¡æœ‰æ‰¾åˆ°å­—å¹•")
            return None
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context = []
        for sub in range_subs:
            context.append(f"[{sub['index']}] {sub['start_time']:.2f}s-{sub['end_time']:.2f}s: {sub['text']}")
        
        context_text = '\n'.join(context)
        
        # è®¡ç®—æ¨èçš„æ—¶é•¿èŒƒå›´
        # æŒ‰ç…§ 6å­—/ç§’ çš„TTSè¯­é€Ÿè®¡ç®—
        text_length = len(narration_text)
        estimated_tts_duration = text_length / 6.0
        min_duration = max(duration, estimated_tts_duration) + 0.5
        max_duration = max(duration, estimated_tts_duration) + 3.0
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªè§†é¢‘å‰ªè¾‘ä¸“å®¶ã€‚ç°åœ¨éœ€è¦ä¸ºä»¥ä¸‹æ—ç™½æ‰¾åˆ°æœ€åŒ¹é…çš„è§†é¢‘ç‰‡æ®µã€‚

æ—ç™½æ–‡æœ¬: {narration_text}
æ—ç™½æ–‡æœ¬é•¿åº¦: {text_length} å­—
**å®é™…éŸ³é¢‘æ—¶é•¿: {duration:.2f} ç§’** â† è¿™æ˜¯çœŸå®çš„TTSéŸ³é¢‘é•¿åº¦ï¼

å¯é€‰çš„è§†é¢‘ç‰‡æ®µï¼ˆåŸå§‹å­—å¹•ï¼‰:
{context_text}

**ğŸš¨ æ ¸å¿ƒè¦æ±‚ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰**:
1. **è§†é¢‘ç‰‡æ®µæ€»æ—¶é•¿ MUST >= {min_duration:.1f}ç§’**ï¼ˆéŸ³é¢‘æ—¶é•¿ {duration:.2f}s + 0.5sç¼“å†²ï¼‰
2. **å®å¯é€‰é•¿ï¼Œä¸èƒ½é€‰çŸ­ï¼** çŸ­äº†ä¼šå¯¼è‡´è§£è¯´å¡é¡¿ï¼
3. å¯ä»¥é€‰æ‹©å¤šä¸ªä¸è¿ç»­ç‰‡æ®µæ‹¼æ¥ï¼Œåªè¦æ€»æ—¶é•¿å¤Ÿ
4. æœ€å¤§æ—¶é•¿ä¸è¶…è¿‡ {max_duration:.1f}ç§’

é€‰æ‹©ç­–ç•¥:
- ä¼˜å…ˆé€‰æ‹©å†…å®¹ç›¸å…³ä¸”ç”»é¢ç²¾å½©çš„ç‰‡æ®µ
- å¦‚æœå•ä¸ªç‰‡æ®µä¸å¤Ÿé•¿ï¼Œ**å¿…é¡»é€‰æ‹©å¤šä¸ªç‰‡æ®µæ‹¼æ¥**
- ç‰‡æ®µå†…å®¹è¦ä¸æ—ç™½æ„æ€ç›¸å…³
- æ¯æ®µå†…éƒ¨å¿…é¡»è¿ç»­ï¼ˆå¦‚ [10-15]ï¼‰ï¼Œä½†æ®µä¸æ®µä¹‹é—´å¯ä»¥è·³è·ƒï¼ˆå¦‚ [10-15] + [25-30]ï¼‰

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼Œåªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹:
{{
  "clips": [
    {{
      "start_line": <èµ·å§‹è¡Œå·>,
      "end_line": <ç»“æŸè¡Œå·>,
      "start_time": <å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰>,
      "end_time": <ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰>,
      "duration": <ç‰‡æ®µæ—¶é•¿ï¼ˆç§’ï¼‰>,
      "reason": "<ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªç‰‡æ®µ>"
    }}
    // å¯ä»¥æœ‰å¤šä¸ªç‰‡æ®µï¼ŒæŒ‰æ’­æ”¾é¡ºåºæ’åˆ—
  ],
  "total_duration": <æ‰€æœ‰ç‰‡æ®µæ€»æ—¶é•¿ï¼ˆç§’ï¼‰>,  â† **å¿…é¡» >= {min_duration:.1f}ç§’ï¼**
  "confidence": <åŒ¹é…åº¦ 0-1>,
  "quality_score": <è´¨é‡è¯„åˆ† 0-100>,
  "match_level": "<åŒ¹é…ç­‰çº§: excellent|good|acceptable|poor|none>",
  "content_match": "<å†…å®¹åŒ¹é…è¯´æ˜>",
  "issues": ["<å¯èƒ½å­˜åœ¨çš„é—®é¢˜åˆ—è¡¨>"]
}}

è¯„åˆ†æ ‡å‡†:
- excellent (90-100): å†…å®¹é«˜åº¦ç›¸å…³ï¼Œç”»é¢ç²¾å½©ï¼Œæ€»æ—¶é•¿ >= {min_duration:.1f}s
- good (70-89): å†…å®¹ç›¸å…³ï¼Œç”»é¢åˆé€‚ï¼Œæ€»æ—¶é•¿ >= {min_duration:.1f}s
- acceptable (50-69): å†…å®¹éƒ¨åˆ†ç›¸å…³ï¼Œæ€»æ—¶é•¿ >= {min_duration:.1f}sï¼ˆåˆšå¥½å¤Ÿï¼‰
- poor (30-49): å†…å®¹å‹‰å¼ºç›¸å…³ **æˆ– æ€»æ—¶é•¿ < {min_duration:.1f}s**ï¼ˆä¼šå¡é¡¿ï¼ï¼‰
- none (0-29): å‡ ä¹æ— ç›¸å…³å†…å®¹æˆ–æ€»æ—¶é•¿ä¸¥é‡ä¸è¶³

**âš ï¸ é‡è¦**: å¦‚æœæ€»æ—¶é•¿ < {min_duration:.1f}ç§’ï¼Œè¯„åˆ†æœ€é«˜åªèƒ½æ˜¯ poor (30-49åˆ†)ï¼

**ç¤ºä¾‹è¿”å›ï¼ˆå¤šç‰‡æ®µï¼‰**:
{{
  "clips": [
    {{"start_line": 10, "end_line": 15, "start_time": 20.5, "end_time": 25.3, "duration": 4.8, "reason": "åŸºå¾·å‡ºç°ç”»é¢"}},
    {{"start_line": 25, "end_line": 30, "start_time": 50.2, "end_time": 56.1, "duration": 5.9, "reason": "é¢„å‘Šä¿¡ç‰¹å†™"}}
  ],
  "total_duration": 10.7,
  "confidence": 0.9,
  "quality_score": 92,
  "match_level": "excellent",
  "content_match": "ç²¾ç¡®åŒ¹é…åŸºå¾·é¢„å‘Šä¿¡åœºæ™¯",
  "issues": []
}}
"""
        
        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å‰ªè¾‘åŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æå­—å¹•å¹¶é€‰æ‹©æœ€ä½³è§†é¢‘ç‰‡æ®µã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            
            # å¤„ç†å¤šç‰‡æ®µè¿”å›æ ¼å¼
            if 'clips' in result and isinstance(result['clips'], list) and len(result['clips']) > 0:
                # å¤šç‰‡æ®µæ¨¡å¼ï¼šä¿å­˜æ‰€æœ‰ç‰‡æ®µä¿¡æ¯ç”¨äºåç»­æ‹¼æ¥
                clips_info = []
                total_duration = 0.0
                
                for clip in result['clips']:
                    start_line = clip['start_line']
                    end_line = clip['end_line']
                    
                    start_sub = next((s for s in range_subs if s['index'] == start_line), None)
                    end_sub = next((s for s in range_subs if s['index'] == end_line), None)
                    
                    if not start_sub or not end_sub:
                        print(f"  âš ï¸ è·³è¿‡ç‰‡æ®µ: æ— æ³•æ‰¾åˆ°è¡Œå· {start_line}-{end_line} å¯¹åº”çš„å­—å¹•")
                        continue
                    
                    clip_duration = end_sub['end_time'] - start_sub['start_time']
                    clips_info.append({
                        'start_line': start_line,
                        'end_line': end_line,
                        'start_time': start_sub['start_time'],
                        'end_time': end_sub['end_time'],
                        'duration': clip_duration,
                        'reason': clip.get('reason', '')
                    })
                    total_duration += clip_duration
                
                if not clips_info:
                    print(f"  âš ï¸ æ— æ³•æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆç‰‡æ®µ")
                    return None
                
                # ä¿å­˜æ‰€æœ‰ç‰‡æ®µä¿¡æ¯
                result['clips'] = clips_info
                result['start_line'] = clips_info[0]['start_line']
                result['end_line'] = clips_info[-1]['end_line']
                result['start_time'] = clips_info[0]['start_time']
                result['end_time'] = clips_info[-1]['end_time']
                result['duration'] = total_duration
                result['multi_clip'] = True  # æ ‡è®°ä¸ºå¤šç‰‡æ®µæ¨¡å¼
                
                print(f"  ğŸ“¹ LLMè¿”å›å¤šç‰‡æ®µæ¨¡å¼: {len(clips_info)} ä¸ªç‰‡æ®µï¼Œæ€»æ—¶é•¿ {total_duration:.2f}s")
                for i, clip in enumerate(clips_info, 1):
                    print(f"     ç‰‡æ®µ{i}: è¡Œ{clip['start_line']}-{clip['end_line']}, "
                          f"{clip['start_time']:.1f}s-{clip['end_time']:.1f}s ({clip['duration']:.1f}s) - {clip['reason']}")
                
            else:
                # å…¼å®¹æ—§çš„å•ç‰‡æ®µæ ¼å¼
                start_line = result['start_line']
                end_line = result['end_line']
                
                start_sub = next((s for s in range_subs if s['index'] == start_line), None)
                end_sub = next((s for s in range_subs if s['index'] == end_line), None)
                
                if not start_sub or not end_sub:
                    print(f"  âš ï¸ æ— æ³•æ‰¾åˆ°è¡Œå· {start_line}-{end_line} å¯¹åº”çš„å­—å¹•")
                    return None
                
                # ä½¿ç”¨å­—å¹•çš„çœŸå®æ—¶é—´
                result['start_time'] = start_sub['start_time']
                result['end_time'] = end_sub['end_time']
                result['duration'] = result['end_time'] - result['start_time']
            
            # éªŒè¯æ—¶é—´åŒºé—´
            result = self._validate_clip_duration(result, duration, range_subs)
            
            # è·å–è´¨é‡è¯„åˆ†å’ŒåŒ¹é…ç­‰çº§
            quality_score = result.get('quality_score', 50)
            match_level = result.get('match_level', 'acceptable')
            
            # æ ¹æ®åŒ¹é…ç­‰çº§æ˜¾ç¤ºä¸åŒé¢œè‰²çš„æç¤º
            if match_level == 'excellent':
                level_icon = "\033[32mâœ“ ä¼˜ç§€\033[0m"  # ç»¿è‰²
            elif match_level == 'good':
                level_icon = "\033[36mâœ“ è‰¯å¥½\033[0m"  # é’è‰²
            elif match_level == 'acceptable':
                level_icon = "\033[33mâš  å¯æ¥å—\033[0m"  # é»„è‰²
            elif match_level == 'poor':
                level_icon = "\033[33mâš  è´¨é‡è¾ƒå·®\033[0m"  # æ©™è‰²(ç”¨é»„è‰²ä»£æ›¿)
            else:  # none
                level_icon = "\033[31mâœ— æ— åŒ¹é…\033[0m"  # çº¢è‰²
            
            print(f"  {level_icon} LLM é€‰æ‹©: è¡Œ {result['start_line']}-{result['end_line']}, "
                  f"æ—¶é—´ {result['start_time']:.2f}s-{result['end_time']:.2f}s, "
                  f"æ—¶é•¿ {result['duration']:.2f}s")
            print(f"    è¯„åˆ†: {quality_score}/100 | åŒ¹é…åº¦: {result.get('confidence', 0):.2f}")
            print(f"    å†…å®¹: {result.get('content_match', result.get('reason', 'N/A'))}")
            
            # æ˜¾ç¤ºå¯èƒ½çš„é—®é¢˜
            issues = result.get('issues', [])
            if issues and isinstance(issues, list) and len(issues) > 0:
                for issue in issues:
                    if issue and issue.strip():
                        print(f"    \033[33mâš \033[0m {issue}")
            
            return result
            
        except Exception as e:
            print(f"  âœ— LLM æŸ¥è¯¢å¤±è´¥: {e}")
            # é™çº§ç­–ç•¥ï¼šç®€å•é€‰æ‹©èŒƒå›´å†…çš„å‰å‡ ä¸ªå­—å¹•
            if range_subs:
                total_dur = 0
                selected_subs = []
                for sub in range_subs:
                    if total_dur >= duration:
                        break
                    selected_subs.append(sub)
                    total_dur += (sub['end_time'] - sub['start_time'])
                
                if selected_subs:
                    return {
                        'start_line': selected_subs[0]['index'],
                        'end_line': selected_subs[-1]['index'],
                        'start_time': selected_subs[0]['start_time'],
                        'end_time': selected_subs[-1]['end_time'],
                        'duration': selected_subs[-1]['end_time'] - selected_subs[0]['start_time'],
                        'confidence': 0.5,
                        'quality_score': 40,
                        'match_level': 'poor',
                        'reason': 'é™çº§ç­–ç•¥ï¼šè‡ªåŠ¨é€‰æ‹©',
                        'content_match': 'LLMå¤±è´¥ï¼Œä½¿ç”¨è‡ªåŠ¨é€‰æ‹©ç­–ç•¥',
                        'issues': ['LLMæŸ¥è¯¢å¤±è´¥ï¼Œæ— æ³•è¯„ä¼°åŒ¹é…è´¨é‡']
                    }
            return None
    
    def _validate_clip_duration(self, clip_info: Dict, audio_duration: float, 
                                range_subs: List[Dict]) -> Dict:
        """
        éªŒè¯å¹¶è°ƒæ•´è§†é¢‘ç‰‡æ®µæ—¶é•¿
        
        Args:
            clip_info: LLM è¿”å›çš„ç‰‡æ®µä¿¡æ¯ï¼ˆå·²åŒ…å«çœŸå®å­—å¹•æ—¶é—´ï¼‰
            audio_duration: éŸ³é¢‘æ—¶é•¿
            range_subs: å¯é€‰å­—å¹•èŒƒå›´
            
        Returns:
            è°ƒæ•´åçš„ç‰‡æ®µä¿¡æ¯
        """
        video_duration = clip_info['duration']
        max_allowed = audio_duration + 2.0
        min_required = audio_duration + 0.5
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§å…è®¸é•¿åº¦
        if video_duration > max_allowed:
            print(f"  âš ï¸ è§†é¢‘ç‰‡æ®µè¿‡é•¿: {video_duration:.2f}s > {max_allowed:.2f}s (éŸ³é¢‘+2s)")
            
            # æˆªæ–­è§†é¢‘ï¼šä»èµ·å§‹è¡Œå¼€å§‹ï¼Œæ‰¾åˆ°ç´¯è®¡æ—¶é•¿ä¸è¶…è¿‡ max_allowed çš„æœ€åä¸€è¡Œ
            start_line = clip_info['start_line']
            start_time = clip_info['start_time']
            
            new_end_line = start_line
            new_end_time = start_time
            
            for sub in sorted(range_subs, key=lambda x: x['index']):
                if sub['index'] < start_line:
                    continue
                if sub['index'] > clip_info['end_line']:
                    break
                    
                # æ£€æŸ¥å¦‚æœåŒ…å«è¿™ä¸€è¡Œï¼Œæ€»æ—¶é•¿æ˜¯å¦è¶…é™
                potential_duration = sub['end_time'] - start_time
                if potential_duration <= max_allowed:
                    new_end_line = sub['index']
                    new_end_time = sub['end_time']
                else:
                    break
            
            clip_info['end_line'] = new_end_line
            clip_info['end_time'] = new_end_time
            clip_info['duration'] = new_end_time - start_time
            print(f"  âœ‚ï¸ å·²æˆªæ–­è‡³: {clip_info['duration']:.2f}s, æ–°è¡Œå·èŒƒå›´: {start_line}-{new_end_line}")
        
        # æ£€æŸ¥æ˜¯å¦å¤ªçŸ­
        elif video_duration < min_required:
            print(f"  âš ï¸ è§†é¢‘ç‰‡æ®µç¨çŸ­: {video_duration:.2f}s < {min_required:.2f}s (éŸ³é¢‘+0.5s)")
            
            # å°è¯•å»¶é•¿ï¼šä»å½“å‰ç»“æŸè¡Œå¾€åæ‰¾å­—å¹•
            start_time = clip_info['start_time']
            current_end_line = clip_info['end_line']
            
            new_end_line = current_end_line
            new_end_time = clip_info['end_time']
            
            for sub in sorted(range_subs, key=lambda x: x['index']):
                if sub['index'] <= current_end_line:
                    continue
                    
                # æ£€æŸ¥åŒ…å«è¿™ä¸€è¡Œåçš„æ€»æ—¶é•¿
                potential_duration = sub['end_time'] - start_time
                if potential_duration <= max_allowed:
                    new_end_line = sub['index']
                    new_end_time = sub['end_time']
                    
                    # è¾¾åˆ°æœ€å°è¦æ±‚å°±åœæ­¢
                    if potential_duration >= min_required:
                        break
                else:
                    break
            
            if new_end_line > current_end_line:
                clip_info['end_line'] = new_end_line
                clip_info['end_time'] = new_end_time
                clip_info['duration'] = new_end_time - start_time
                print(f"  â• å·²å»¶é•¿è‡³: {clip_info['duration']:.2f}s, æ–°è¡Œå·èŒƒå›´: {clip_info['start_line']}-{new_end_line}")
        
        return clip_info


class VideoComposer:
    """è§†é¢‘åˆæˆå™¨"""
    
    def __init__(self, timeline_file: str, original_srt_file: str, 
                 original_video_file: str, api_key: str = None):
        """
        åˆå§‹åŒ–è§†é¢‘åˆæˆå™¨
        
        Args:
            timeline_file: timeline.json æ–‡ä»¶è·¯å¾„
            original_srt_file: åŸå§‹å­—å¹•æ–‡ä»¶è·¯å¾„
            original_video_file: åŸå§‹è§†é¢‘æ–‡ä»¶è·¯å¾„
            api_key: DeepSeek API Key
        """
        self.timeline_file = timeline_file
        self.original_srt_file = original_srt_file
        self.original_video_file = original_video_file
        
        # åŠ è½½ timeline
        with open(timeline_file, 'r', encoding='utf-8') as f:
            self.timeline = json.load(f)
        
        # è§£æåŸå§‹å­—å¹•
        print(f"è§£æåŸå§‹å­—å¹•: {original_srt_file}")
        self.subtitles = SRTParser.parse_srt(original_srt_file)
        print(f"  âœ“ å…± {len(self.subtitles)} æ¡å­—å¹•")
        
        # åˆå§‹åŒ– LLM
        self.clip_finder = VideoClipFinder(api_key or "sk-b806e7ca03ab4a9cb12445a659349268")
    
    def generate_video_clips(self, output_dir: str, max_workers: int = 3) -> List[Dict]:
        """
        å¹¶å‘ç”Ÿæˆæ‰€æœ‰è§†é¢‘ç‰‡æ®µ
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            max_workers: æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤3ï¼‰
        
        Returns:
            ç‰‡æ®µåˆ—è¡¨ï¼Œæ¯ä¸ªç‰‡æ®µåŒ…å« video_file, audio_file, subtitle_text, etc.
        """
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        print(f"\nå¼€å§‹å¹¶å‘ç”Ÿæˆè§†é¢‘ç‰‡æ®µï¼ˆå¹¶å‘æ•°: {max_workers}ï¼‰...")
        
        # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨
        tasks = []
        for i, segment in enumerate(self.timeline['segments'], 1):
            tasks.append((i, segment, output_dir))
        
        # å¹¶å‘å¤„ç†
        clips = [None] * len(tasks)  # é¢„åˆ†é…åˆ—è¡¨ï¼Œä¿æŒé¡ºåº
        
        def process_one_clip(task_data):
            i, segment, output_dir = task_data
            
            print(f"\n[{i}/{len(tasks)}] å¤„ç†ç‰‡æ®µ {i}...")
            
            # æå–ä¿¡æ¯
            narration_text = segment['text']
            audio_file = segment['audio_file']
            duration = segment['duration']
            line_start = segment.get('line_range_start')
            line_end = segment.get('line_range_end')
            
            print(f"  æ—ç™½: {narration_text[:50]}...")
            print(f"  è¡Œå·èŒƒå›´: [{line_start}-{line_end}], æ—¶é•¿: {duration:.2f}s")
            
            # ä½¿ç”¨ LLM æŸ¥æ‰¾æœ€ä½³è§†é¢‘ç‰‡æ®µ
            if not line_start or not line_end:
                print(f"  âš  æ²¡æœ‰è¡Œå·èŒƒå›´ï¼Œè·³è¿‡")
                return (i, None)
            
            clip_info = self.clip_finder.find_best_clip(
                narration_text, self.subtitles, 
                line_start, line_end, duration
            )
            
            if not clip_info:
                print(f"  âš  æœªæ‰¾åˆ°åˆé€‚çš„è§†é¢‘ç‰‡æ®µï¼Œè·³è¿‡")
                return (i, None)
            
            # å‰ªè¾‘è§†é¢‘ç‰‡æ®µï¼ˆä¸€æ­¥å®Œæˆï¼šè§†é¢‘+é…éŸ³+å­—å¹•ï¼‰
            video_clip_file = os.path.join(output_dir, f'video_clip_{i:03d}.mp4')
            self._extract_video_clip(
                self.original_video_file,
                clip_info['start_time'],
                clip_info['end_time'],
                video_clip_file,
                audio_file,
                narration_text
            )
            
            # è¿”å›ç‰‡æ®µä¿¡æ¯
            clip_data = {
                'index': i,
                'video_file': video_clip_file,
                'audio_file': audio_file,
                'subtitle_text': narration_text,
                'video_start': clip_info['start_time'],
                'video_end': clip_info['end_time'],
                'video_duration': clip_info['duration'],
                'audio_duration': duration,
                'confidence': clip_info['confidence'],
                'reason': clip_info['reason']
            }
            
            return (i, clip_data)
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æ‰§è¡Œ
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(process_one_clip, task): task for task in tasks}
            
            for future in as_completed(futures):
                i, clip_data = future.result()
                if clip_data:
                    clips[i-1] = clip_data
        
        # è¿‡æ»¤æ‰ None
        clips = [c for c in clips if c is not None]
        
        print(f"\nâœ“ å¹¶å‘å¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(clips)} ä¸ªè§†é¢‘ç‰‡æ®µ")
        return clips
    
    def _extract_video_clip(self, input_video: str, start_time: float, 
                           end_time: float, output_file: str, audio_file: str, subtitle_text: str):
        """
        ä½¿ç”¨ ffmpeg æå–è§†é¢‘ç‰‡æ®µï¼Œå¹¶ç›´æ¥æ·»åŠ é…éŸ³å’Œå­—å¹•
        """
        duration = end_time - start_time
        
        # åˆ›å»ºä¸´æ—¶å­—å¹•æ–‡ä»¶ï¼ˆASSæ ¼å¼ï¼‰
        import tempfile
        srt_file = tempfile.NamedTemporaryFile(mode='w', suffix='.srt', delete=False, encoding='utf-8')
        srt_file.write(f"1\n00:00:00,000 --> {self._format_srt_time(duration)}\n{subtitle_text}\n")
        srt_file.close()
        
        # ä¸€æ­¥å®Œæˆï¼šæå–è§†é¢‘ + æ·»åŠ é…éŸ³ + çƒ§å½•å­—å¹• + è°ƒæ•´ç”»é¢
        cmd = [
            'ffmpeg', '-y',
            '-ss', str(start_time),
            '-i', input_video,
            '-i', audio_file,
            '-t', str(duration),
            '-filter_complex',
            f"[0:v]scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2,subtitles={srt_file.name}:force_style='Fontsize=8,PrimaryColour=&H00FFFFFF,OutlineColour=&H00000000,Outline=2,Shadow=1,MarginV=40,Alignment=2'[vout]",
            '-map', '[vout]',
            '-map', '1:a',
            '-c:v', 'libx264',
            '-preset', 'ultrafast',
            '-crf', '23',
            '-c:a', 'aac',
            '-b:a', '128k',
            output_file
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=120)
            print(f"  âœ“ è§†é¢‘ç‰‡æ®µå·²ä¿å­˜ï¼ˆå«é…éŸ³+å­—å¹•ï¼‰: {output_file}")
        except subprocess.TimeoutExpired:
            print(f"  âœ— æå–è§†é¢‘è¶…æ—¶")
        except subprocess.CalledProcessError as e:
            print(f"  âœ— æå–è§†é¢‘å¤±è´¥: {e}")
            if e.stderr:
                print(f"  é”™è¯¯è¾“å‡º: {e.stderr[-500:]}")
        finally:
            # æ¸…ç†ä¸´æ—¶å­—å¹•æ–‡ä»¶
            try:
                os.unlink(srt_file.name)
            except:
                pass
    
    def _format_srt_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ– SRT æ—¶é—´"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"
    
    def compose_final_video(self, clips: List[Dict], output_file: str):
        """
        åˆæˆæœ€ç»ˆè§†é¢‘ï¼ˆç›´æ¥åˆå¹¶æ‰€æœ‰ç‰‡æ®µï¼Œå› ä¸ºå·²ç»åŒ…å«é…éŸ³å’Œå­—å¹•ï¼‰
        """
        print(f"\nå¼€å§‹åˆæˆæœ€ç»ˆè§†é¢‘...")
        
        # åˆ›å»ºåˆå¹¶åˆ—è¡¨
        temp_dir = os.path.dirname(output_file)
        concat_file = os.path.join(temp_dir, 'concat_list.txt')
        
        with open(concat_file, 'w', encoding='utf-8') as f:
            for clip in clips:
                f.write(f"file '{clip['video_file']}'\n")
        
        # ç›´æ¥åˆå¹¶
        cmd = [
            'ffmpeg', '-y',
            '-f', 'concat',
            '-safe', '0',
            '-i', concat_file,
            '-c', 'copy',
            output_file
        ]
        
        try:
            subprocess.run(cmd, capture_output=True, check=True)
            print(f"\nâœ“ æœ€ç»ˆè§†é¢‘å·²ä¿å­˜: {output_file}")
        except subprocess.CalledProcessError as e:
            print(f"\nâœ— åˆå¹¶è§†é¢‘å¤±è´¥: {e}")
        
        # æ¸…ç†
        if os.path.exists(concat_file):
            os.remove(concat_file)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='è§†é¢‘åˆæˆå™¨ - æ ¹æ® timeline.json å‰ªè¾‘è§†é¢‘')
    parser.add_argument('timeline', help='timeline.json æ–‡ä»¶è·¯å¾„')
    parser.add_argument('original_srt', help='åŸå§‹å­—å¹•æ–‡ä»¶è·¯å¾„ (å¦‚ 1732974958319.srt)')
    parser.add_argument('original_video', help='åŸå§‹è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', default='final_video.mp4', help='è¾“å‡ºè§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--clip-dir', default='video_clips', help='è§†é¢‘ç‰‡æ®µè¾“å‡ºç›®å½•')
    parser.add_argument('-w', '--workers', type=int, default=3, help='å¹¶å‘æ•° (é»˜è®¤ 3)')
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("è§†é¢‘åˆæˆå™¨")
    print("=" * 80)
    print(f"Timeline: {args.timeline}")
    print(f"åŸå§‹å­—å¹•: {args.original_srt}")
    print(f"åŸå§‹è§†é¢‘: {args.original_video}")
    print(f"è¾“å‡ºæ–‡ä»¶: {args.output}")
    print(f"å¹¶å‘æ•°: {args.workers}")
    print("=" * 80)
    
    # åˆ›å»ºåˆæˆå™¨
    composer = VideoComposer(
        timeline_file=args.timeline,
        original_srt_file=args.original_srt,
        original_video_file=args.original_video
    )
    
    # ç”Ÿæˆè§†é¢‘ç‰‡æ®µï¼ˆå¹¶å‘ï¼‰
    clips = composer.generate_video_clips(args.clip_dir, max_workers=args.workers)
    
    # ä¿å­˜ç‰‡æ®µä¿¡æ¯
    clips_info_file = os.path.join(args.clip_dir, 'clips_info.json')
    with open(clips_info_file, 'w', encoding='utf-8') as f:
        json.dump(clips, f, ensure_ascii=False, indent=2)
    print(f"\nâœ“ ç‰‡æ®µä¿¡æ¯å·²ä¿å­˜: {clips_info_file}")
    
    # åˆæˆæœ€ç»ˆè§†é¢‘
    composer.compose_final_video(clips, args.output)
    
    print("\n" + "=" * 80)
    print("âœ“ å…¨éƒ¨å®Œæˆï¼")
    print("=" * 80)


if __name__ == "__main__":
    main()
